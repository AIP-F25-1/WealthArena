{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Finetune Intent Classification Model\n",
        "\n",
        "This notebook demonstrates how to fine-tune a DistilBERT model for intent classification on financial text data. We'll:\n",
        "\n",
        "1. **Install required packages** - transformers, datasets, evaluate, scikit-learn, accelerate\n",
        "2. **Load and prepare data** - CSV files with text and intent labels\n",
        "3. **Map intents to IDs** - Convert intent labels to numerical IDs for training\n",
        "4. **Tokenize the data** - Convert text to model inputs using DistilBERT tokenizer\n",
        "5. **Train the model** - Fine-tune DistilBERT for configurable epochs using Hugging Face Trainer\n",
        "6. **Evaluate performance** - Compute accuracy, macro F1-score, and confusion matrix\n",
        "7. **Save the model** - Store the fine-tuned model and tokenizer\n",
        "8. **Test inference speed** - Measure how fast the model can make predictions\n",
        "9. **Save metrics** - Export performance metrics to JSON\n",
        "\n",
        "## What is Intent Classification?\n",
        "\n",
        "Intent classification is the process of determining what a user wants to accomplish based on their text input. In financial contexts, this helps us understand whether users are asking about:\n",
        "\n",
        "- **price**: Questions about stock prices, market values, or asset pricing\n",
        "  - *\"What's the current price of AAPL?\"*\n",
        "  - *\"How much is Bitcoin worth today?\"*\n",
        "  - *\"Show me Tesla's stock price\"*\n",
        "\n",
        "- **news**: Requests for financial news, market updates, or company announcements\n",
        "  - *\"What's the latest news about Microsoft?\"*\n",
        "  - *\"Any recent updates on the tech sector?\"*\n",
        "  - *\"Show me today's market news\"*\n",
        "\n",
        "- **explain**: Requests for explanations of financial concepts, terms, or strategies\n",
        "  - *\"What is a dividend yield?\"*\n",
        "  - *\"Explain what P/E ratio means\"*\n",
        "  - *\"How does compound interest work?\"*\n",
        "\n",
        "- **portfolio**: Questions about portfolio management, asset allocation, or investment strategies\n",
        "  - *\"How should I diversify my portfolio?\"*\n",
        "  - *\"What's a good asset allocation for retirement?\"*\n",
        "  - *\"Should I rebalance my investments?\"*\n",
        "\n",
        "- **other**: General queries that don't fit into the above categories\n",
        "  - *\"Hello, how are you?\"*\n",
        "  - *\"What can you help me with?\"*\n",
        "  - *\"Thanks for your help\"*\n",
        "\n",
        "This classification enables financial assistants to route queries to appropriate handlers and provide more targeted responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Training Parameters\n",
        "# Configure training parameters here for easy modification\n",
        "\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 128\n",
        "LEARNING_RATE = 2e-5\n",
        "WARMUP_STEPS = 500\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "print(\"[CONFIG] Training Parameters:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Max Length: {MAX_LEN}\")\n",
        "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"  Warmup Steps: {WARMUP_STEPS}\")\n",
        "print(f\"  Weight Decay: {WEIGHT_DECAY}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Install Required Packages\n",
        "\n",
        "First, let's install the necessary dependencies for our intent classification project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package if not already available.\"\"\"\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"[OK] {package} already available\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"[WORKING] Installing {package}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "            print(f\"[OK] {package} installed successfully\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"[ERROR] Failed to install {package}: {e}\")\n",
        "            return False\n",
        "\n",
        "# Install required packages\n",
        "packages = [\"transformers\", \"datasets\", \"evaluate\", \"scikit-learn\", \"accelerate\"]\n",
        "for package in packages:\n",
        "    install_package(package)\n",
        "\n",
        "print(\"[SUCCESS] All packages ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Import Libraries and Set Up\n",
        "# Import all necessary libraries for our intent classification project\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Transformers and training\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification, \n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "# Datasets and evaluation\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"[OK] All libraries imported successfully!\")\n",
        "print(f\"[INFO] Current working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Load and Explore the Data\n",
        "\n",
        "We'll load our intent classification dataset from CSV files. The data should have:\n",
        "- **text**: The financial text to classify (questions, requests, statements, etc.)\n",
        "- **intent**: Intent labels (price, news, explain, portfolio, other)\n",
        "\n",
        "Let's load the train, validation, and test sets and explore their structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "data_dir = Path(\"..\") / \"data\"  # Go up one level from notebooks/ directory\n",
        "train_df = pd.read_csv(data_dir / \"intent_train.csv\")\n",
        "val_df = pd.read_csv(data_dir / \"intent_val.csv\")\n",
        "test_df = pd.read_csv(data_dir / \"intent_test.csv\")\n",
        "\n",
        "print(\"[DATA] Dataset Overview:\")\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "print(f\"Test samples: {len(test_df)}\")\n",
        "print()\n",
        "\n",
        "# Display sample data\n",
        "print(\"[INFO] Sample training data:\")\n",
        "print(train_df.head())\n",
        "print()\n",
        "\n",
        "# Check intent distribution\n",
        "print(\"[STATS] Intent distribution in training set:\")\n",
        "print(train_df['intent'].value_counts().sort_index())\n",
        "print()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"[CHECK] Data quality check:\")\n",
        "print(f\"Missing values in train: {train_df.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in val: {val_df.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in test: {test_df.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Map Intents to IDs\n",
        "\n",
        "Machine learning models work with numerical labels, so we need to convert our intent strings to numerical IDs. We'll create a mapping between intent names and IDs, then apply this mapping to all our datasets.\n",
        "\n",
        "This step is crucial for:\n",
        "- **Model training**: Neural networks require numerical inputs\n",
        "- **Consistency**: Ensuring the same intent always maps to the same ID\n",
        "- **Interpretability**: Being able to convert predictions back to readable intent names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get unique intents from training data\n",
        "unique_intents = sorted(train_df['intent'].unique())\n",
        "print(f\"[INFO] Found {len(unique_intents)} unique intents: {unique_intents}\")\n",
        "\n",
        "# Create intent-to-ID mapping\n",
        "intent2id = {intent: idx for idx, intent in enumerate(unique_intents)}\n",
        "id2intent = {idx: intent for intent, idx in intent2id.items()}\n",
        "\n",
        "print(\"\\n[MAPPING] Intent to ID mapping:\")\n",
        "for intent, idx in intent2id.items():\n",
        "    print(f\"  {intent} → {idx}\")\n",
        "\n",
        "# Apply mapping to all datasets\n",
        "train_df['label'] = train_df['intent'].map(intent2id)\n",
        "val_df['label'] = val_df['intent'].map(intent2id)\n",
        "test_df['label'] = test_df['intent'].map(intent2id)\n",
        "\n",
        "# Verify mapping worked correctly\n",
        "print(\"\\n[VERIFY] Sample mappings:\")\n",
        "for i in range(min(5, len(train_df))):\n",
        "    print(f\"  '{train_df.iloc[i]['intent']}' → {train_df.iloc[i]['label']}\")\n",
        "\n",
        "# Check for any unmapped values (NaN)\n",
        "unmapped_train = train_df['label'].isna().sum()\n",
        "unmapped_val = val_df['label'].isna().sum()\n",
        "unmapped_test = test_df['label'].isna().sum()\n",
        "\n",
        "if unmapped_train + unmapped_val + unmapped_test > 0:\n",
        "    print(f\"\\n[WARNING] Found unmapped intents:\")\n",
        "    print(f\"  Train: {unmapped_train}, Val: {unmapped_val}, Test: {unmapped_test}\")\n",
        "else:\n",
        "    print(\"\\n[SUCCESS] All intents mapped successfully!\")\n",
        "\n",
        "num_labels = len(unique_intents)\n",
        "print(f\"\\n[CONFIG] Number of intent classes: {num_labels}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Set Up DistilBERT Tokenizer and Model\n",
        "\n",
        "DistilBERT is a smaller, faster version of BERT that maintains most of BERT's performance while being much more efficient. We'll use it for our intent classification task.\n",
        "\n",
        "The tokenizer converts text into tokens (subwords) that the model can understand. We'll also set up the model architecture for sequence classification with the correct number of intent classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up model and tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "print(f\"🤖 Loading {model_name}...\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load model for sequence classification with correct number of labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=num_labels,\n",
        "    id2label=id2intent,\n",
        "    label2id=intent2id\n",
        ")\n",
        "\n",
        "print(\"✅ Model and tokenizer loaded successfully!\")\n",
        "print(f\"📏 Model parameters: {model.num_parameters():,}\")\n",
        "print(f\"🔤 Tokenizer vocab size: {tokenizer.vocab_size:,}\")\n",
        "print(f\"🎯 Number of intent classes: {num_labels}\")\n",
        "print(f\"📋 Intent classes: {list(intent2id.keys())}\")\n",
        "\n",
        "# Test tokenization\n",
        "sample_text = \"What's the current price of Apple stock?\"\n",
        "tokens = tokenizer(sample_text, return_tensors=\"pt\")\n",
        "print(f\"\\n🧪 Tokenization test:\")\n",
        "print(f\"Original text: {sample_text}\")\n",
        "print(f\"Token IDs: {tokens['input_ids'].squeeze().tolist()}\")\n",
        "print(f\"Attention mask: {tokens['attention_mask'].squeeze().tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Prepare and Tokenize the Data\n",
        "\n",
        "Now we'll convert our pandas DataFrames into Hugging Face Dataset objects and tokenize the text. This step is crucial for preparing the data in the format the model expects.\n",
        "\n",
        "We'll create a tokenization function that:\n",
        "1. Takes text and labels\n",
        "2. Tokenizes the text with the DistilBERT tokenizer\n",
        "3. Handles padding and truncation automatically\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert pandas DataFrames to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "print(\"📦 Datasets converted to Hugging Face format\")\n",
        "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"Validation dataset: {len(val_dataset)} samples\")\n",
        "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
        "\n",
        "# Define tokenization function\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize the text data for the model\"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=MAX_LEN,  # Use configurable max length\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Tokenize all datasets\n",
        "print(\"\\n🔄 Tokenizing datasets...\")\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"✅ Tokenization complete!\")\n",
        "print(f\"📊 Sample tokenized input shape: {train_dataset[0]['input_ids'].shape}\")\n",
        "print(f\"📊 Sample attention mask shape: {train_dataset[0]['attention_mask'].shape}\")\n",
        "print(f\"📊 Sample label: {train_dataset[0]['label']} ({id2intent[train_dataset[0]['label']]})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Set Up Training Configuration\n",
        "\n",
        "Before we start training, we need to configure the training arguments. This includes:\n",
        "- **Learning rate**: How fast the model learns (too high = unstable, too low = slow)\n",
        "- **Batch size**: How many examples to process at once\n",
        "- **Epochs**: How many times to see the entire dataset\n",
        "- **Evaluation strategy**: When to check model performance\n",
        "- **Logging**: How often to log training progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up training arguments using configurable parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./intent_model\",               # Directory to save model checkpoints\n",
        "    num_train_epochs=EPOCHS,                   # Number of training epochs (configurable)\n",
        "    per_device_train_batch_size=BATCH_SIZE,    # Batch size for training (configurable)\n",
        "    per_device_eval_batch_size=BATCH_SIZE,     # Batch size for evaluation (configurable)\n",
        "    learning_rate=LEARNING_RATE,               # Learning rate (configurable)\n",
        "    warmup_steps=WARMUP_STEPS,                 # Number of warmup steps (configurable)\n",
        "    weight_decay=WEIGHT_DECAY,                 # Weight decay for regularization (configurable)\n",
        "    logging_dir=\"./logs\",                      # Directory for logs\n",
        "    logging_steps=100,                         # Log every 100 steps\n",
        "    evaluation_strategy=\"epoch\",               # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",                     # Save model at the end of each epoch\n",
        "    load_best_model_at_end=True,              # Load the best model at the end\n",
        "    metric_for_best_model=\"eval_accuracy\",     # Metric to use for best model selection\n",
        "    greater_is_better=True,                    # Higher accuracy is better\n",
        "    report_to=None,                            # Disable wandb/tensorboard logging\n",
        "    seed=42,                                   # Random seed for reproducibility\n",
        ")\n",
        "\n",
        "print(\"[CONFIG] Training configuration:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  Output directory: {training_args.output_dir}\")\n",
        "print(f\"  Evaluation strategy: {training_args.evaluation_strategy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Set Up Evaluation Metrics\n",
        "\n",
        "We need to define how to compute evaluation metrics during training. We'll track:\n",
        "- **Accuracy**: Percentage of correct predictions\n",
        "- **Macro F1-score**: Harmonic mean of precision and recall, averaged across all intent classes\n",
        "\n",
        "The `compute_metrics` function will be called automatically during training to evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy and F1-score for evaluation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_macro': f1\n",
        "    }\n",
        "\n",
        "print(\"📊 Evaluation metrics configured:\")\n",
        "print(\"- Accuracy: Percentage of correct predictions\")\n",
        "print(\"- F1-macro: Macro-averaged F1-score across all intent classes\")\n",
        "print(\"✅ Ready for training!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Train the DistilBERT Model\n",
        "\n",
        "Now it's time to train our intent classification model! This is where the magic happens:\n",
        "\n",
        "1. **Data Collator**: Handles dynamic padding for efficient batching\n",
        "2. **Trainer**: Manages the entire training process\n",
        "3. **Training**: Fine-tune DistilBERT for 3 epochs on our financial intent data\n",
        "\n",
        "The training process will:\n",
        "- Process batches of text through the model\n",
        "- Compute loss and gradients\n",
        "- Update model weights\n",
        "- Evaluate on validation set after each epoch\n",
        "- Save the best performing model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"🚀 Starting training...\")\n",
        "print(\"⏱️ This may take several minutes depending on your hardware\")\n",
        "print(\"📊 Training progress will be displayed below:\")\n",
        "print()\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n✅ Training completed successfully!\")\n",
        "print(f\"💾 Best model saved to: {training_args.output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Evaluate Model Performance\n",
        "\n",
        "Now let's evaluate our fine-tuned model on the test set to see how well it performs. We'll compute:\n",
        "\n",
        "1. **Accuracy**: Overall correctness\n",
        "2. **Macro F1-score**: Balanced performance across all intent classes\n",
        "3. **Confusion Matrix**: Detailed breakdown of predictions vs. actual labels\n",
        "\n",
        "This gives us a comprehensive view of the model's performance on unseen data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"🧪 Evaluating model on test set...\")\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "print(\"\\n📊 Test Set Performance:\")\n",
        "print(f\"🎯 Accuracy: {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"📈 Macro F1-Score: {test_results['eval_f1_macro']:.4f}\")\n",
        "\n",
        "# Get predictions for confusion matrix\n",
        "print(\"\\n🔍 Computing detailed predictions...\")\n",
        "test_predictions = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
        "test_labels = test_predictions.label_ids\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "class_names = [id2intent[i] for i in range(num_labels)]\n",
        "\n",
        "print(f\"\\n📋 Confusion Matrix:\")\n",
        "print(\"Rows = Actual, Columns = Predicted\")\n",
        "print(\"     \", \" \".join([f\"{name:>10}\" for name in class_names]))\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{name:>10}: {' '.join([f'{cm[i,j]:>10}' for j in range(len(class_names))])}\")\n",
        "\n",
        "# Calculate per-class metrics\n",
        "print(f\"\\n📊 Per-class Performance:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    precision = cm[i, i] / cm[:, i].sum() if cm[:, i].sum() > 0 else 0\n",
        "    recall = cm[i, i] / cm[i, :].sum() if cm[i, :].sum() > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    print(f\"{class_name:>10}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Visualize Confusion Matrix\n",
        "\n",
        "Let's create a visual representation of the confusion matrix to better understand the model's performance. This heatmap will show us:\n",
        "- **Diagonal elements**: Correct predictions (higher = better)\n",
        "- **Off-diagonal elements**: Misclassifications (lower = better)\n",
        "- **Color intensity**: Number of samples in each category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Intent Classification Model')\n",
        "plt.xlabel('Predicted Intent')\n",
        "plt.ylabel('Actual Intent')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate and display normalized confusion matrix\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Normalized Confusion Matrix - Intent Classification Model')\n",
        "plt.xlabel('Predicted Intent')\n",
        "plt.ylabel('Actual Intent')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Confusion Matrix Analysis:\")\n",
        "print(\"- Darker blue = more samples\")\n",
        "print(\"- Diagonal = correct predictions\")\n",
        "print(\"- Off-diagonal = misclassifications\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Save the Fine-tuned Model\n",
        "\n",
        "Now we'll save our trained model and tokenizer to the `models/intent-finetuned` directory. This allows us to:\n",
        "- **Reuse the model** for future predictions\n",
        "- **Share the model** with others\n",
        "- **Deploy the model** in production applications\n",
        "\n",
        "The saved model includes both the architecture and the learned weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "model_save_path = Path(\"../models/intent-finetuned\")\n",
        "model_save_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"💾 Saving model to: {model_save_path}\")\n",
        "\n",
        "# Save the model and tokenizer\n",
        "trainer.save_model(str(model_save_path))\n",
        "tokenizer.save_pretrained(str(model_save_path))\n",
        "\n",
        "# Also save the intent mappings for future use\n",
        "mappings = {\n",
        "    \"intent2id\": intent2id,\n",
        "    \"id2intent\": id2intent,\n",
        "    \"num_labels\": num_labels\n",
        "}\n",
        "\n",
        "with open(model_save_path / \"intent_mappings.json\", 'w') as f:\n",
        "    json.dump(mappings, f, indent=2)\n",
        "\n",
        "print(\"✅ Model, tokenizer, and mappings saved successfully!\")\n",
        "print(f\"📁 Files saved in: {model_save_path}\")\n",
        "\n",
        "# List the saved files\n",
        "saved_files = list(model_save_path.glob(\"*\"))\n",
        "print(f\"\\n📋 Saved files:\")\n",
        "for file in saved_files:\n",
        "    print(f\"  - {file.name}\")\n",
        "\n",
        "# Verify the model can be loaded\n",
        "print(f\"\\n🔍 Verifying saved model...\")\n",
        "try:\n",
        "    # Load the saved model\n",
        "    loaded_model = AutoModelForSequenceClassification.from_pretrained(str(model_save_path))\n",
        "    loaded_tokenizer = AutoTokenizer.from_pretrained(str(model_save_path))\n",
        "    print(\"✅ Model and tokenizer loaded successfully from saved files!\")\n",
        "    print(f\"📏 Loaded model parameters: {loaded_model.num_parameters():,}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading saved model: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Test Inference Speed\n",
        "\n",
        "In real-world applications, inference speed is crucial. We'll measure how fast our model can make predictions on individual examples. This is important for:\n",
        "- **Real-time applications**: Chatbots, live intent classification\n",
        "- **Batch processing**: Analyzing large volumes of text\n",
        "- **User experience**: Fast response times\n",
        "\n",
        "We'll test with multiple examples representing different intents and calculate the average inference time in milliseconds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test inference speed\n",
        "print(\"⚡ Testing inference speed...\")\n",
        "\n",
        "# Sample texts for testing different intents\n",
        "test_texts = [\n",
        "    \"What's the current price of Apple stock?\",  # price\n",
        "    \"Show me the latest news about Tesla\",       # news\n",
        "    \"What is a P/E ratio?\",                      # explain\n",
        "    \"How should I diversify my portfolio?\",      # portfolio\n",
        "    \"Hello, how are you today?\",                 # other\n",
        "    \"What's Bitcoin worth right now?\",           # price\n",
        "    \"Any updates on the tech sector?\",           # news\n",
        "    \"Explain compound interest to me\",           # explain\n",
        "    \"Should I rebalance my investments?\",        # portfolio\n",
        "    \"Thanks for your help!\"                      # other\n",
        "]\n",
        "\n",
        "# Load the saved model for inference\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained(str(model_save_path))\n",
        "inference_tokenizer = AutoTokenizer.from_pretrained(str(model_save_path))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "inference_model.eval()\n",
        "\n",
        "# Measure inference time\n",
        "inference_times = []\n",
        "predictions = []\n",
        "\n",
        "print(f\"\\n🧪 Testing inference on {len(test_texts)} examples:\")\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    # Tokenize input\n",
        "    inputs = inference_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN)\n",
        "    \n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.no_grad():  # Disable gradient computation for faster inference\n",
        "        outputs = inference_model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    inference_time_ms = (end_time - start_time) * 1000\n",
        "    inference_times.append(inference_time_ms)\n",
        "    predictions.append(prediction)\n",
        "    \n",
        "    # Get intent label\n",
        "    predicted_intent = id2intent[prediction]\n",
        "    \n",
        "    print(f\"  {i+1:2d}. '{text[:40]}...' → {predicted_intent:>9} ({inference_time_ms:.2f}ms)\")\n",
        "\n",
        "# Calculate statistics\n",
        "avg_inference_time = np.mean(inference_times)\n",
        "min_inference_time = np.min(inference_times)\n",
        "max_inference_time = np.max(inference_times)\n",
        "\n",
        "print(f\"\\n📊 Inference Speed Results:\")\n",
        "print(f\"⚡ Average inference time: {avg_inference_time:.2f}ms\")\n",
        "print(f\"🏃 Fastest inference: {min_inference_time:.2f}ms\")\n",
        "print(f\"🐌 Slowest inference: {max_inference_time:.2f}ms\")\n",
        "print(f\"📈 Throughput: {1000/avg_inference_time:.1f} predictions/second\")\n",
        "\n",
        "# Store the average inference time for metrics\n",
        "inference_ms = avg_inference_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 15: Save Performance Metrics\n",
        "\n",
        "Finally, let's save all our performance metrics to a JSON file. This creates a permanent record of our model's performance that can be:\n",
        "- **Compared** with other models\n",
        "- **Tracked** over time as we improve the model\n",
        "- **Shared** with stakeholders\n",
        "- **Used** for model selection and deployment decisions\n",
        "\n",
        "The metrics file will include accuracy, macro F1-score, and inference speed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all metrics\n",
        "metrics = {\n",
        "    \"accuracy\": float(test_results['eval_accuracy']),\n",
        "    \"f1_macro\": float(test_results['eval_f1_macro']),\n",
        "    \"inference_ms\": float(inference_ms),\n",
        "    \"num_labels\": num_labels,\n",
        "    \"intent_classes\": list(intent2id.keys())\n",
        "}\n",
        "\n",
        "# Save metrics to JSON file\n",
        "metrics_file = \"../metrics_intent.json\"\n",
        "with open(metrics_file, 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"📊 Performance Metrics Summary:\")\n",
        "print(f\"🎯 Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
        "print(f\"📈 Macro F1-Score: {metrics['f1_macro']:.4f}\")\n",
        "print(f\"⚡ Average Inference Time: {metrics['inference_ms']:.2f}ms\")\n",
        "print(f\"🎯 Number of Intent Classes: {metrics['num_labels']}\")\n",
        "print(f\"📋 Intent Classes: {', '.join(metrics['intent_classes'])}\")\n",
        "print(f\"💾 Metrics saved to: {metrics_file}\")\n",
        "\n",
        "# Display the saved metrics\n",
        "print(f\"\\n📋 Saved metrics content:\")\n",
        "with open(metrics_file, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(\"\\n🎉 Intent Classification Model Training Complete!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"✅ Model trained and evaluated successfully\")\n",
        "print(\"✅ Model saved to models/intent-finetuned/\")\n",
        "print(\"✅ Performance metrics saved to metrics_intent.json\")\n",
        "print(\"✅ Ready for production use!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Summary\n",
        "\n",
        "Congratulations! You've successfully fine-tuned a DistilBERT model for financial intent classification. Here's what we accomplished:\n",
        "\n",
        "### ✅ What We Built\n",
        "- **Fine-tuned DistilBERT** for intent classification on financial text\n",
        "- **Mapped intents to IDs** for proper model training\n",
        "- **Trained for 3 epochs** with proper validation\n",
        "- **Comprehensive evaluation** with accuracy, macro F1-score, and confusion matrix\n",
        "- **Saved model and tokenizer** with intent mappings for future use\n",
        "- **Measured inference speed** for production readiness\n",
        "- **Documented performance metrics** in JSON format\n",
        "\n",
        "### 🎯 Intent Classes Supported\n",
        "- **price**: Stock prices, market values, asset pricing queries\n",
        "- **news**: Financial news, market updates, company announcements\n",
        "- **explain**: Explanations of financial concepts, terms, strategies\n",
        "- **portfolio**: Portfolio management, asset allocation, investment advice\n",
        "- **other**: General queries that don't fit specific categories\n",
        "\n",
        "### 📊 Key Features\n",
        "- **Production-ready**: Includes speed testing and model saving\n",
        "- **Comprehensive evaluation**: Multiple metrics and visualizations\n",
        "- **Reproducible**: Fixed random seeds and clear documentation\n",
        "- **Extensible**: Easy to add new intent classes or modify existing ones\n",
        "\n",
        "### 🚀 Next Steps\n",
        "1. **Deploy the model** in a financial chatbot or API\n",
        "2. **Test on new data** to validate performance\n",
        "3. **Experiment with hyperparameters** to improve results\n",
        "4. **Add more intent classes** as needed for your use case\n",
        "5. **Collect more training data** to further improve performance\n",
        "\n",
        "### 📁 Files Created\n",
        "- `models/intent-finetuned/` - Saved model, tokenizer, and intent mappings\n",
        "- `metrics_intent.json` - Performance metrics\n",
        "- Training logs in `./logs/` directory\n",
        "\n",
        "The model is now ready for real-world intent classification in financial applications!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Finetune Intent Classification Model\n",
        "\n",
        "This notebook finetunes an intent classification model for trading-related queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "import os\n",
        "\n",
        "# Set up model and tokenizer for intent classification\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)  # teach, analyze, risk, trade, general\n",
        "\n",
        "print(\"Intent classification model and tokenizer loaded!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
